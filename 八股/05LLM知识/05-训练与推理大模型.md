# 训练（微调）大模型

## SFT

> https://zhuanlan.zhihu.com/p/809229182

### 数据
1. 多样性，包括不限于prompt的多样性、answer的多样性。其中多样性又包含长度多样、类型多样（用户的输入有作业性、有短文本性等等）、内容多样（行业、宏观、公司）

2. 在收集数据过程中，prompt添加示例 COT等等环节，但是训练过程会去掉这些，让模型推理的速度提升，且避免过于仿照示例。

3. 低成本收集数据，用R1请求500条，专门训练一个7B小模型来完成这类数据集的大规模构建。但是实际结果来看，在专业性要求比较高的研报写作上，效果还是很差，毕竟R1生成的内容都需要专业研究员来审核。

4. PROMPT的精写，研究员+算法写初版 -> 大模型优化 -> 研究员+算法再调整 -> 将业务上通病问题添加到PROMPT中

5. 线上用户数据回流，人工分类优劣数据，进行DPO、KTO训练

6. 鲁棒性增强，特定收集一些prompt差但是answer好的数据

7. 不输出嵌套多的JSON，改为其他格式，因为JSON格式输出的标点较多，占token数量

8. rag 的训练 sft 数据构造主要有几个细节需要留意：【正文生成prompt的注意事项】  
a. 检索内容为空的时候模型会怎么回复，别让它自由发挥出一些奇怪的结果；  
b. 检索内容相互矛盾的情况，别让他只盯着第一条 / 最后一条的内容回复；  
c. 检索内容和 query 完全无关的情况，也是需要让模型见过，防止出奇怪的结果；  
d. 检索内容错了。那就让模型照着错的答案念，千万别想着让模型自己判断 rag 的知识和自己的知识谁更正确。  

### 评价
直接用模型进行定义的各维度打分效果不好，模型打分的结果和人差别较大，且模型不太容易给出较低的分数。因此，选择了对比评测的方式。

1. 让模型生成3次结果，用3次结果和之前的结果进行好、坏、平的评价。  
2. 人工评测模型生成的某一次结果，人工维度打分。

## 拒绝采样


## LORA

> https://www.zhihu.com/question/599396505/answer/3141866148

LoRA的本质就是用更少的训练参数【低秩，通过一个较低维度的表示来近似表示一个高维矩阵】来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。

LoRA的做法是在LLM的某些矩阵（ $\boldsymbol{W} \in \mathbb{R}^{d \times k}$ ）旁插入一个和它并行的新的权值矩阵（$\Delta \boldsymbol{W} \in \mathbb{R}^{d \times k}$），但是因为模型的低秩性的存在，我们可以将 $\Delta \boldsymbol{W}$拆分成降维矩阵（$\boldsymbol{A} \in \mathbb{R}^{r \times k}$） 和升维矩阵（$\boldsymbol{B} \in \mathbb{R}^{d \times r}$），其中r很小，从而实现了以极小的参数数量训练LLM。

参数初始化：如图所示，矩阵A为高斯分布初始化；矩阵B为全0初始化。这样训练刚开始时，就不会有噪声（和没有AB是一样的）。

论文中，对于Transformers模型，LORA作用于$W_q$ $W_k$ $W_v$ $W_o$ 且 r = 2。最好的方式是在所有的权值矩阵都加上LoRA，因为这样有利于模型捕捉到所有矩阵的关键信息。

![alt text](lora.png)

# 推理大模型

## 参数

### TOP-P
在每一步，只从累积概率超过某个阈值 p 的最小单词集合中进行随机采样，而不考虑其他低概率的单词。这种方法也被称为核采样（nucleus sampling），因为它只关注概率分布的核心部分，而忽略了尾部部分。
例如，如果 p=0.9，那么我们只从累积概率达到 0.9 的最小单词集合中选择一个单词，而不考虑其他累积概率小于 0.9 的单词。这样可以避免采样到一些不合适或不相关的单词，同时也可以保留一些有趣或有创意的单词。

### TOP-K
选择概率排名前K个的token

### 温度
语言模型首先根据之前的上下文计算词汇表中每个词的非归一化对数概率。
然后将这些对数概率除以 Temperature 值：log_prob_scaled = log_prob / temperature
经过 Temperature 缩放后，应用 softmax 函数将这些缩放后的对数概率转换为总和为 1 的概率分布。
所以，Temperature < 1，这会使得对数概率更极端（即更高的对数概率更高、更低的对数概率更低）；Temperature > 1，它则会起到相反的作用，使得对数概率变得不那么极端，趋向于 0。

如果Temperature = 0，模型每次输出的内容都会是一样的。

## Beam Search
TODO