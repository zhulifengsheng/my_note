# 工作流式（workflow）的多章节并行文章生成【deep research】
#TODO是需要学习的知识点

技术方案的变化历程
首先，文章生成的流程为 用户输入标题 -> 大纲生成 -> 研究思路生成 -> 正文生成（搜索 + 写作）

1. 大纲生成
    1. **真实研报抽取+改写**：
        之前的问题：
        改进：显然应该学习真实研报，但是真实研报的标题形容词丰富、都是作者基于正文润色的（如：智驾平权落地，品牌势能向上 -> 智能驾驶技术研发情况；大力改革，苦修内功 -> 管理层与股权结构分析），而我们项目的大纲标题初始生成的时候是一个无观点的标题（xx公司基本面分析、xx行业分析），所以用LLM对真实研报的大纲进行抽取改写得到数据集。【真实研报的抽取 minerU工具（PDF解析工具）进行文档解析，然后利用模型进行标题识别，得到一二级标题的大纲】
    2. **维度全面、补充特定公司资料**：
        之前的问题：真实研报集中往往分析某些利好的方面（因为作者在写作之前已经知道要写什么），所以真实研报的维度是不全面的。
        改进：因为我们不知道要提前研究什么，所以期望生成维度全面的大纲结构。这里我们取上市公司最近的中年报中经营分析章节【这里使用了GRAPH_RAG的技术#TODO】，加入PROMPT中全维度分析公司的各个方面，所以我们用GPT对原数据集改造+人工校对的方式得到了新数据集。
    3. **在正文生成结束润色形成带观点**：
        之前的问题：大纲标题过于直白，没有观点。（正如第一点提到的）
        改进：基于正文对标题进行润色，发现R1生成的结果语言风格与专业性表现都很好、且这种简单任务也没有幻觉问题，用R1做模型蒸馏构建数据集。
    4. **专题报告（大纲不是维度全面的、而是专注的）生成**：
        之前的问题：用户可能不想对公司做全维度的分析，只想分析公司的营收、某个业务的发展情况等等专题研究。（线上之后收集用户输入的标题发现的问题）
        改进：开始的时候用GPT构建专题大纲数据集但是效果不好，改成r1模型之后效果大幅提升，专题报告的专业性强。
    5. **支持用户指令输入【仿OPENAI-deep research】**：
        之前的问题：1. 用户目前只能上传标题 或者 自己的大纲，不能写一段话来进行大纲生成，期望新的交互更智能、更像AI产品。 2. 用户输入的信息太少了、目前只有标题。
        改进：1. 仿OPENAI的交互模型，用户输入->模型澄清->用户反馈->大纲生成 2. 在大纲这一步将研究思路一并生成，各个标题下的研究思路聚焦于用户的反馈 3. 研究思路从之前的分点列举改为一段逻辑性更强的文字，指导正文生成（deep research模式）。3. 在生成大纲之前进行信息搜索，这也是之前没有的


2. 研究思路生成（RAG搜索+embedding -> Agent式串行 -> deep search深度搜索思考（受openai启发，在核对时传入高质量且有效的研究思路））
    1. **RAG搜索+embedding**：
        之前的问题：
        改进：用title检索网页、切分、相关性判断、LLM生成关键词作为研究思路。
    2. **Agent式串行 ReACT**：
        之前的问题：研究思路的粒度太粗，仅分成了几个宽泛的点
        改进：设计了二级的研究思路结构从粗到细，并结合了Agent进行搜素工具的调用
    3. **deep search深度搜索思考**：
        之前的问题：同上第5条
        改进：xxx

3. 搜索（公司内部的搜索接口 和 博查、秘塔等有差距），总结与过滤（从网页分段embedding -> LLM总结）
    - 金融指标数据的搜索
        - 什么是金融指标（以时间为序列的数值）
        新能源汽车:产量:当月值、GDP:全国
    
        - 为什么用金融指标
        核心是画图，然后可以让正文素材来源引用规范、真实，体现公司数据丰富
    
        - 如何检索出适合的金融指标
        （embedding（没有联想能力、embedding效果相关性也不佳） -> LLM（按行业构建指标库【人工+LLM】、利用真实研报的图文信息【失败】） -> 正文写完反向找指标增强【利用R1推理能力，生成聚合指标图】）

    - 搜索接口即是Agent工具
        - 公司公告
        - 研究报告
        - bing
        - 金融指标
        - 公司数据接口（分产品营收、公司股权结构）
    
    - 总结与过滤
        - 总结 + 补充质量、主题一致性判断（GPT判断得没有很准，例：三星 兴三星）（从网页分段embedding -> LLM总结）

4. 正文生成
    - GPT蒸馏 -> R1蒸馏（幻觉多+AI校对、人工校对复杂）

5. 特定章节写作
    - 投资建议（重要章节）
    搜索大概率找不到合适的素材、如：PE、分产品营收、同比公司
    - 风险提示（不重要章节）
    章节短、不必搜索


# 用户金融指标查询
query -> search    -> subquery -> Embedding（Top50） -> 编辑距离补充 + 精筛（最多 Top5）
      -> no search -> Embedding

## 例子
query：汽车上游金融成本价格 -> 

search：1. search query：汽车产业上游金融有那些 2. 检索的文本xxxx -> 

subquery：铝价格、铜价格、xxx -> 

Embedding：上海期货交易所:铝:每日价（20个指标） -> 

（编辑距离：补充查找同比、环比等信息 -> ）

精筛：LLM（复合指标聚类召回）

## 问题
1. 如何判断search 和 no search
一个prompt完成拆分判断+search query的生成。LLM做得不错，没有大问题，蒸馏数据。

search query有人工的修改，也有自动生成修改（LLM改写5个query，返回搜索结果之后进行对比，选搜索结果最好的query）。

2. subquery的训练
数据集：人工 + 自动合成（金融指标的自然语言 -> LLM生成多个query，取embedding分数最高的）

3. embedding的训练
bge-base + 正负样本训练（人工标注）

4. 评价
人工评价（好 中 差） + 自动评价（相似度分数（好 中 差） + 和上一个版本的对比）


# DEEP RESEARCH 金融研报写作

## 澄清+用户反馈

是否训练？否
为什么没有训练？大模型基座的表现足够强
输入和输出是什么？输入是用户随意写的写作要求，输出是AI生成的澄清问题

亮点：1. 线上发现用户不爱澄清，后面让模型生成多个选项，用户做选择而不是写，同时保留一个写的窗口（每个问题的回答 + 一个用户额外补充的问题）
*那为什么希望用户做澄清，而不是跳过澄清*：1. 产品层面，给用户感觉是一个更智能的系统 2. 内容通过用户澄清聚焦之后，写作出来的文字会更有深度（广度搜索少一些，深度搜索多一些）。

## 大纲

是否训练？是
训练的数据集是怎么来的？有的用R1从真实研报中抽取，有的用公司提供的能力来解析PDF中的目录
数据集样本数？1000 SFT + 100 DPO
训练是怎么做的？第一阶段SFT + 第二阶段DPO（格式DPO，负例为3级大纲、超长/短大纲）
输入和输出是什么？输入是用户写作要求 + 澄清 + 用户反馈，输出是两级标题结构的大纲

亮点：1. 回流线上badcase做dpo，正样本来自人工标注
细节：1. 做LORA训练时，SFT的LORA adapter会被DPO用来继续在其上进行训练

## 研究目的（写作逻辑）

## Deep research
### 搜索

### 总结

### 检查

# 正文生成

# 可视化

# 大纲润色


# 天工

## TODO List

## Agent

## 记忆管理

## 


# 为什么要找工作（去大的平台，有好的发展），对业务的看法（做机器翻译现在没有了因为大模型，感悟：持续跟踪最前沿的技术，业务上使用好的技术，如果新技术效果好，我们就迭代、保持对新技术的尝试）
