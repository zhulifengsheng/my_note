[TOC]

# 深度学习分类

1. 有监督学习
2. 无监督学习
   - 自监督学习：
     1. 生成式学习：自编码器（Auto-Encoder），主要用于数据的降维或者特征的抽取，训练方法是重建输入
     1. 对比式学习：对比学习，训练方法是区分正负样本
3. 半监督学习：有一些数据有标记，给没有标记的数据指明了方向



# 有监督学习

1. MT
2. image classification



# 无监督学习

## 自监督学习（通过自定义的有监督学习方式，挖掘数据信息）

为下游的有监督任务学习提供良好的representation，即通过自监督学习学习到泛化性能很强的representation

### 自编码器

结构：1. encoder：它可以把原先的图像压缩成更低维度的向量【得到一个低维的高度抽象的向量，起到**压缩数据、获取主要信息**的效果】。 2. decoder：它可以把压缩后的向量还原成图像，通常它们使用的都是神经网络。

![在这里插入图片描述](01-autoencoder1.png)

**多个自编码器模型：**

1. de-nosing auto-encoder

![image-20220619160512551](01-autoencoder2.png)

2. feature disentangle

   encoder学习（压缩）得到的特征会包含很多的信息，比如对一段声音进行压缩就会包含语音内容和发言者音色、音调等信息。那有没有一种方法可以将这些信息区分开呢？比如，下图将content和speaker的信息区分开。

   如果可以成功地将声音信号encode出来的向量中**内容和音色区分开**，那么给两段声音（A说你好，B说再见），就可以做到变声的效果（A说再见，B说你好）。

   ![image-20220619160912561](01-autoencoder3.png)

3. variational auto encoder（生成模型）

   现在，我们让AE去训练还原月球照片，接下来我们在code空间中，取全月和半月照片编码的中间点，我们期望模型可以生成一个3/4月的照片，但是AE是做不到的【左图】。为了解决这个问题，我们引入了噪声，使得图片的编码区域得到扩大，从而掩盖掉失真的空白编码点【中图】。不过这还不够充分，我们可以进一步将噪声拉大，拉成无限长，让他的编码覆盖整个code空间，同时我们还保证在原编码附近的概率最大，越远离原编码概率越小【右图】。

   ![](01-vae2.jpg)![](01-vae3.jpg)![](01-vae4.jpg)

   ------

   为了实现这一目标，VAE应运而生，**VAE的作用原理：**【从左图到右图，encoder将输入从一个确定的空间点编码成一个空间上的分布（概率分布）】

   VAE的理论基础源于高斯混合模型【任何一个分布，都可以看作是若干个高斯分布的叠加】，我们可以将encoder编码的code看作是概率图模型中的隐变量z【z服从着某个未知的概率分布】，那么encoder的工作就是建模q(z|x)【得到一个概率分布】，decoder的工作就是建模P(x|z)【从z的概率分布中的采样一个z'，还原回x】。

   **我们先进行一个假设**：前面提到过，希望x经过encoder的编码，可以得到一个覆盖整个code空间的分布，所以我们先验地认为q(z|x)服从正态分布。
   
   我们利用encoder来拟合q(z|x)，得到均值$\mu$和方差$\delta$
   
   ------
   
   如果只有这些的话，显然是不行的，因为神经网络在拟合的过程中，只要让方差$\delta$等于0，就相当于取消加入噪声，取消了随机性，又返回了AE那种code是一个确定的点的状态了。所以，VAE要让模型拟合的q(z|x)向标准正态分布看齐。
   
   **我们再进行一个假设**：$Z∼N(0,1)$
   
   通过在loss中加入$KL(q(z|x)||p(z))$来实现这一看齐过程
   
   现在，VAE就是用encoder将x建模为某个分布z，从z中采样一个出来送入decoder进行x的还原
   
   ------
   
   从数学角度入手：我们求解的目标是最大化$P(x) = \int_zp(x,z)dz = \int_zp(z)p(x|z)dz$【一个边缘概率的求解过程，极大似然估计】，不过这个式子无法求解，这导致$p(z|x) = \frac{P(z)p(x|z)}{p(x)}$也是无法求解的，所以我们需要另寻他法，利用神经网络来拟合p(z|x)。
   
   再回到我们希望的求解目标上，现在：
   $$
   \begin{aligned}
   \log P(x) &= \int_zq(z|x)\log p(x)dz  \space\space\space (q(z|x) 是 encoder 的输出)\\
   &= \int_zq(z|x) \log(\frac{p(z,x)}{p(z|x)})dz \\
   &= \int_zq(z|x) \log(\frac{p(z,x)}{q(z|x)}\times\frac{q(z|x)}{p(z|x)})dz \\
   &= \int_zq(z|x) \log(\frac{p(z,x)}{q(z|x)})dz+\int_zq(z|x)\log(\frac{q(z|x)}{p(z|x)})dz \\
   &= \int_zq(z|x) \log(\frac{p(x|z)p(z)}{q(z|x)})dz + KL(q(z|x)||p(z|x)) \\
   &\ge \int_zq(z|x) \log(\frac{p(x|z)p(z)}{q(z|x)})dz【下界】\\
   &= \int_zq(z|x) \log(\frac{p(z)}{q(z|x)})dz + \int_zq(z|x) \log p(x|z)dz\\
   &= -KL(q(z|x)||p(z)) + \int_zq(z|x) \log p(x|z)dz \\
   &= E_{q(z|x)}[\log p(x|z)] - KL(q(z|x)||p(z)) \\
   &= 重构loss + KL\space loss
   \end{aligned}
   $$
   
   ------
   
   因为采样是不可以求导的，所以我们使用重采样技巧：
   
   下图是VAE结构图，我们的做法是让encoder生成两个code，一个是$\mu$，另一个是控制噪声干扰程度的编码$\sigma$【它是为了给高斯噪声e分配权重，这些高斯分布就是给模型加入的随机性，代表了一个采样的过程】。右下角的loss是为了防止encoder编码出来的随机变量权重$\sigma$为负无穷，导致模型没有给code加入噪声。【即KL loss】
   
   ![](01-vae.png)
   

### 对比学习

